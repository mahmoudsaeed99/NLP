{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fadfa6f6",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846bb9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to C:\\Users\\Mahmoud\n",
      "[nltk_data]     Saeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mahmoud\n",
      "[nltk_data]     Saeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19961c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050ab31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive = twitter_samples.strings(\"positive_tweets.json\")\n",
    "all_negative = twitter_samples.strings(\"negative_tweets.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed2fa5",
   "metadata": {},
   "source": [
    "# Explore and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a713c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_positive) , len(all_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e60fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data two pieces train and test\n",
    "train_pos = all_positive[:4000]\n",
    "test_pos = all_positive[4000:]\n",
    "train_neg = all_negative[:4000]\n",
    "test_neg = all_negative[4000:]\n",
    "\n",
    "all_train = train_pos + train_neg\n",
    "all_test = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d56b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.append(np.ones((len(train_pos),1)) , np.zeros((len(train_neg) , 1)) , axis = 0)\n",
    "test_y = np.append(np.ones((len(test_pos) , 1)) , np.zeros((len(test_neg) , 1)) , axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1454533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y) , len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b262008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    stemmer = PorterStemmer()\n",
    "    lemma = WordNetLemmatizer()\n",
    "    stop_words = stopwords.words('english')\n",
    "    # remove links\n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+' , '' , tweet)\n",
    "    #remove hash\n",
    "    tweet = re.sub(r'#' , '' , tweet)\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # tokenize tweets\n",
    "    token = TweetTokenizer()\n",
    "    tweet_token = token.tokenize(tweet)\n",
    "    clean_tweets = []\n",
    "    pos = nltk.pos_tag(tweet_token)\n",
    "    for word , pos in zip(tweet_token,pos):\n",
    "        if (word not in stop_words and word not in string.punctuation):\n",
    "#             stem_word = stemmer.stem(word)\n",
    "            lemma_word = lemma.lemmatize(word)\n",
    "            if pos[1] == 'VBN':\n",
    "                clean_tweets.append(stemmer.stem(lemma_word))\n",
    "                continue\n",
    "            clean_tweets.append(lemma_word)\n",
    "    return clean_tweets        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f735896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mahmoud',\n",
       " 'saeed',\n",
       " 'graduat',\n",
       " 'faculty',\n",
       " 'computer',\n",
       " 'Artificial',\n",
       " 'Intelligence']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_tweet(\"i am mahmoud saeed graduated from faculty of computers and Artificial Intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb1e5e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freq(tweets , ys):\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "    \n",
    "    freqs = {}\n",
    "    for y , tweet in zip(yslist , tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word , y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "    return freqs           \n",
    "     \n",
    "freqs =  build_freq(all_train ,train_y)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61912f8e",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94231ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    h = 1 / (1 + np.exp(-1 * z))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b68397b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "#test sigmoid function \n",
    "if sigmoid(0) == 0.5:\n",
    "    print(\"success\")\n",
    "else:\n",
    "    print(\"faild!\")\n",
    "    \n",
    "if sigmoid(4.92) == 0.9927537604041685:\n",
    "    print(\"success\")\n",
    "else:\n",
    "    print(\"faild!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bce8a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x , y , theta , alpha , num_iter):\n",
    "    '''\n",
    "        Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    '''\n",
    "    for _ in range(num_iter):    \n",
    "        z = np.dot(x,theta)\n",
    "        h = sigmoid(z)\n",
    "        J = -1/x.shape[0] * (np.dot(np.transpose(y) , np.log(h)) + np.dot(np.transpose(1 - y) , np.log(1 -h)))\n",
    "        theta = theta - (alpha / x.shape[0]) * np.dot(np.transpose(x) , (h - y))\n",
    "        \n",
    "    J = float(J)\n",
    "    return J , theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb88aeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.67094970.\n",
      "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
     ]
    }
   ],
   "source": [
    "# Check the function\n",
    "# Construct a synthetic test case using numpy PRNG functions\n",
    "np.random.seed(1)\n",
    "# X input is 10 x 3 with ones for the bias terms\n",
    "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
    "# Y Labels are 10 x 1\n",
    "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
    "\n",
    "# Apply gradient descent\n",
    "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
    "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa3db1",
   "metadata": {},
   "source": [
    "### Extracting Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3242bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(tweet , freq , process_tweet = process_tweet):\n",
    "    words = process_tweet(tweet)\n",
    "    x = np.zeros((1,3))\n",
    "    x[0,0] = 1\n",
    "    for word in words:\n",
    "        x[0,1] += freq[(word,1)] if (word,1) in freq else 0\n",
    "        x[0,2] += freq[(word,0)] if (word,0) in freq else 0\n",
    "        \n",
    "    assert(x.shape == (1,3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a9d787a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1. 145.  77.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s = \"mahmoud is a good person\"\n",
    "test = extract_feature(s,freqs)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38d9d6",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd8a66",
   "metadata": {},
   "source": [
    "### Trainig model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcccc994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.23121757.\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(all_train),3))\n",
    "for i in range(len(all_train)):\n",
    "    X[i ,:] = extract_feature(all_train[i] , freqs)\n",
    "    \n",
    "Y = train_y\n",
    "J , theta = gradientDescent(X , Y , np.zeros((3,1)) , 1e-9, 1500)\n",
    "print(f\"The cost after training is {J:.8f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03288a61",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3681e3",
   "metadata": {},
   "source": [
    "$$y_{pred} = sigmoid(\\mathbf{x} \\cdot \\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ffda592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet(tweet , freqs , theta):\n",
    "    x = extract_feature(tweet , freqs)\n",
    "    y_pred = sigmoid(np.dot(x , theta))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83c982",
   "metadata": {},
   "source": [
    "### check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8653df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(test_x , test_y , freqs , theta , predict_tweet = predict_tweet):\n",
    "    y_hat = []\n",
    "    \n",
    "    for tweet in test_x:\n",
    "        y_predict = predict_tweet(tweet , freqs , theta)\n",
    "        if y_predict > 0.5:\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            y_hat.append(0)\n",
    "            \n",
    "    accuracy = np.sum(test_y.reshape(1, test_y.shape[0]) == y_hat) / len(y_hat)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b10062f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9815"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(all_test ,test_y , freqs , theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6661a868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'ridiculously', 'bright', 'movie', 'The', 'plot', 'terrible', 'I', 'sad', 'ending']\n",
      "[[0.42110572]]\n",
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
    "print(process_tweet(my_tweet))\n",
    "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Positive sentiment')\n",
    "else: \n",
    "    print('Negative sentiment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
